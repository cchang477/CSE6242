{"cells":[{"cell_type":"code","execution_count":66,"id":"e7e5dd9f","metadata":{},"outputs":[],"source":["import pandas as pd\n","\n","import pyspark\n","from pyspark.sql import SparkSession\n","from pyspark.sql.functions import  *\n","from pyspark.sql.types import StringType\n","from pyspark.ml.clustering import BisectingKMeans\n","from pyspark.ml.feature import VectorAssembler\n","\n","from sklearn.cluster import KMeans, AgglomerativeClustering\n","from sklearn.metrics import silhouette_score, calinski_harabasz_score\n"]},{"cell_type":"markdown","id":"7c7c1faf","metadata":{},"source":["## Data Preprocessing"]},{"cell_type":"code","execution_count":2,"id":"43755856","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["# load dataframe from raw data\n","gcp_storage_path = 'gs://lance-bucket/all_reviews.csv'\n","sdf = spark.read.csv(gcp_storage_path,\n","                        sep=\",\",                # Specify the delimiter (default is comma)\n","                        header=True,           # Use the first line as header\n","                        inferSchema=True,      # Automatically infer the schema of the DataFrame\n","                        escape='\"',            # Character used to escape quotes\n","                        nullValue=\"NULL\",      # Specify what represents a null value\n","                        quote='\"',             # Character used for quoting\n","                        mode=\"DROPMALFORMED\"   # Ignore malformed lines\n","                    )\n","\n","# create clean date & month column\n","sdf = sdf.withColumn(\"created_date\", to_date(trim(sdf['date']), 'MMM d, yyyy'))\n","sdf = sdf.drop('date')\n","sdf = sdf.withColumn(\"created_month\", date_format(\"created_date\", \"yyyy-MM\"))\n","\n","# Extract firm from firm_link using regex\n","sdf = sdf.withColumn(\"extracted_text\", regexp_extract(\"firm_link\", r\"Reviews/(.*?)\\.htm\", 1))\n","sdf = sdf.withColumn(\"firm\", regexp_extract(\"extracted_text\", r\"^(.*?)-Reviews\", 1))\n","sdf = sdf.drop('extracted_text')"]},{"cell_type":"code","execution_count":6,"id":"e291b812","metadata":{},"outputs":[],"source":["# Filtering to useful records\n","clean_sdf = sdf.filter(\n","                (sdf['rating'].isNotNull())\n","                & (sdf['pros'].isNotNull())\n","                & (sdf['cons'].isNotNull())\n","                & (sdf['firm'].isNotNull())\n","            )"]},{"cell_type":"code","execution_count":9,"id":"27c19157","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["# write parquet\n","clean_sdf.write.format(\"parquet\").mode(\"overwrite\").save(\"gs://lance-bucket/clean_reviews_processed_parquet\")"]},{"cell_type":"markdown","id":"5dca53a8","metadata":{},"source":["## Data Modelling"]},{"cell_type":"code","execution_count":7,"id":"078e41b5","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["\r","[Stage 3:>                                                          (0 + 1) / 1]\r","\r","                                                                                \r"]}],"source":["# load parquet\n","gcp_storage_path = 'gs://lance-bucket/clean_reviews_processed_parquet'\n","clean_sdf = spark.read.parquet(gcp_storage_path,\n","                        sep=\",\",                # Specify the delimiter (default is comma)\n","                        header=True,           # Use the first line as header\n","                        inferSchema=True,      # Automatically infer the schema of the DataFrame\n","                        escape='\"',            # Character used to escape quotes\n","                        nullValue=\"NULL\",      # Specify what represents a null value\n","                        quote='\"',             # Character used for quoting\n","                        mode=\"DROPMALFORMED\"   # Ignore malformed lines\n","                    )"]},{"cell_type":"code","execution_count":null,"id":"1af4ddcc","metadata":{},"outputs":[],"source":["# aggregating by firm for average scores\n","agg_sdf = clean_sdf.groupBy('firm').agg(count('rating').alias('review_count')\n","                              , round(avg('Career Opportunities'),2).alias('opportunities')\n","                              , round(avg('Compensation and Benefits'),2).alias('compensation')\n","                              , round(avg('Senior Management'),2).alias('management')\n","                              , round(avg('Work/Life Balance'),2).alias('worklife_balance')\n","                              , round(avg('Culture & Values'),2).alias('culture')\n","                              , round(avg('Diversity & Inclusion'),2).alias('diversity')\n","                             ).orderBy('review_count', ascending=False)\n","\n","# keep only firms with at least 100 reviews, and dop any firms without any of the scores\n","agg_sdf = agg_sdf.filter(col('review_count')>=100).dropna()"]},{"cell_type":"code","execution_count":null,"id":"9ea2bafa","metadata":{},"outputs":[],"source":["## Performing BKM clustering\n","\n","# Select specific columns for clustering\n","X_sdf = agg_sdf.select('opportunities', 'compensation', 'management', 'worklife_balance', 'culture', 'diversity')\n","\n","# Create a VectorAssembler to combine the features into a single column\n","assembler = VectorAssembler(inputCols=['opportunities', 'compensation', 'management', 'worklife_balance', 'culture', 'diversity'], outputCol='features')\n","features_df = assembler.transform(X_sdf)\n","\n","# Initialize Bisecting K-Means\n","bkm = BisectingKMeans(k=4, minDivisibleClusterSize=1.0, maxIter=20)\n","\n","# Fit the model on the features DataFrame\n","model = bkm.fit(features_df)\n","\n","# Get the cluster predictions\n","predictions = model.transform(features_df)"]},{"cell_type":"code","execution_count":60,"id":"a8b9fea4","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/miniconda3/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n","  super()._check_params_vs_input(X, default_n_init=10)\n"]}],"source":["# converting spark dataframe to pandas\n","df = agg_sdf.toPandas()\n","\n","# creating training dataset\n","X = df.drop(columns='review_count').set_index('firm')\n","\n","# K-Means Clustering\n","kmeans = KMeans(n_clusters=4, random_state=42)\n","df['kmeans_labels'] = kmeans.fit_predict(X)\n","\n","\n","# Agglomerative Clustering\n","agg_clustering = AgglomerativeClustering(n_clusters=4, linkage='ward')\n","df['agg_labels'] = agg_clustering.fit_predict(X)\n","\n","\n","# Append bkm predictions to pandas\n","bkm_labels = predictions.toPandas()\n","df['bkm_labels'] = bkm_labels['prediction']"]},{"cell_type":"code","execution_count":70,"id":"b65f173c","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","**Silhouette Scores**\n","\n","Measures how similar each point is to its cluster compared to other clusters.\n","Values range from -1 to 1 (1 indicates dense, well-separated clusters).\n","\n","kmeans: 0.24338014396503294\n","agg: 0.19155056420430813\n","bkm: 0.033337252036037254\n","\n","**Clinski-Harabasz Scores**\n","\n","The ratio of the sum of between-cluster dispersion to within-cluster dispersion.\n","A higher score indicates better-defined clusters.\n","\n","kmeans: 4079.72302470041\n","agg: 3623.716263747032\n","bkm: 938.123266908293\n","\n","\n"]}],"source":["# model evaluation via silhouette scores\n","kmeans_silhouette = silhouette_score(X, df['kmeans_labels'])\n","agg_silhouette = silhouette_score(X, df['agg_labels'])\n","bkm_silhouette = silhouette_score(X, df['bkm_labels'])\n","\n","# model evaluation via calinski harabasz scores\n","kmeans_ch_score = calinski_harabasz_score(X, df['kmeans_labels'])\n","agg_ch_score = calinski_harabasz_score(X, df['agg_labels'])\n","bkm_ch_score = calinski_harabasz_score(X, df['bkm_labels'])\n","\n","\n","print(f\"\"\"\n","**Silhouette Scores**\n","\n","Measures how similar each point is to its cluster compared to other clusters.\n","Values range from -1 to 1 (1 indicates dense, well-separated clusters).\n","\n","kmeans: {kmeans_silhouette}\n","agg: {agg_silhouette}\n","bkm: {bkm_silhouette}\n","\n","**Clinski-Harabasz Scores**\n","\n","The ratio of the sum of between-cluster dispersion to within-cluster dispersion.\n","A higher score indicates better-defined clusters.\n","\n","kmeans: {kmeans_ch_score}\n","agg: {agg_ch_score}\n","bkm: {bkm_ch_score}\n","\n","\"\"\")\n"]},{"cell_type":"code","execution_count":null,"id":"cf332b9e","metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"b4fb37e6","metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"ca8c004b","metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"PySpark","language":"python","name":"pyspark"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"}},"nbformat":4,"nbformat_minor":5}